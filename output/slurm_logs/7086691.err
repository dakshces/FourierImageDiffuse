2024-12-07 18:18:52.486095: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-12-07 18:18:52.665073: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/ffmpeg-7.0-xny2fb2nz3demdcjhj6x74mcxz4iwmys/lib:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/libiconv-1.17-jwjcds2nmpz7gpstqq22vty7jxldvpec/lib:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/cuda-12.3.0-r72aozfqcf6mc3jurx6ndsw6kbcvmd2d/lib64:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/glew-2.2.0-plawm2jod5t5dzga2ktzstlqjp4fjt4q/lib64:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/boost-1.80.0-harukoycghoq6exyzhd3jonvup3gpqeo/lib:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/zstd-1.5.5-zokfqscxl2bxqzikz5ftrnx6ugyaw4m5/lib:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/mesa-22.1.6-6dbg5gqcfhgvls2kyds4s5qk4xgrltkw/lib:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/zlib-1.2.13-jv5y5e7lstxpe7urzow6wr42b44vclu3/lib:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/expat-2.5.0-zujcztprogy4dznn7eu65xext6qeih4r/lib:/usr/lib/nvidia
2024-12-07 18:18:52.665116: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.
2024-12-07 18:18:53.845368: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/ffmpeg-7.0-xny2fb2nz3demdcjhj6x74mcxz4iwmys/lib:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/libiconv-1.17-jwjcds2nmpz7gpstqq22vty7jxldvpec/lib:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/cuda-12.3.0-r72aozfqcf6mc3jurx6ndsw6kbcvmd2d/lib64:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/glew-2.2.0-plawm2jod5t5dzga2ktzstlqjp4fjt4q/lib64:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/boost-1.80.0-harukoycghoq6exyzhd3jonvup3gpqeo/lib:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/zstd-1.5.5-zokfqscxl2bxqzikz5ftrnx6ugyaw4m5/lib:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/mesa-22.1.6-6dbg5gqcfhgvls2kyds4s5qk4xgrltkw/lib:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/zlib-1.2.13-jv5y5e7lstxpe7urzow6wr42b44vclu3/lib:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/expat-2.5.0-zujcztprogy4dznn7eu65xext6qeih4r/lib:/usr/lib/nvidia
2024-12-07 18:18:53.845492: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/ffmpeg-7.0-xny2fb2nz3demdcjhj6x74mcxz4iwmys/lib:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/libiconv-1.17-jwjcds2nmpz7gpstqq22vty7jxldvpec/lib:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/cuda-12.3.0-r72aozfqcf6mc3jurx6ndsw6kbcvmd2d/lib64:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/glew-2.2.0-plawm2jod5t5dzga2ktzstlqjp4fjt4q/lib64:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/boost-1.80.0-harukoycghoq6exyzhd3jonvup3gpqeo/lib:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/zstd-1.5.5-zokfqscxl2bxqzikz5ftrnx6ugyaw4m5/lib:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/mesa-22.1.6-6dbg5gqcfhgvls2kyds4s5qk4xgrltkw/lib:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/zlib-1.2.13-jv5y5e7lstxpe7urzow6wr42b44vclu3/lib:/oscar/rt/9.2/software/0.20-generic/0.20.1/opt/spack/linux-rhel9-x86_64_v3/gcc-11.3.1/expat-2.5.0-zujcztprogy4dznn7eu65xext6qeih4r/lib:/usr/lib/nvidia
2024-12-07 18:18:53.845511: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.
Global seed set to 23
/oscar/scratch/daggarw5/latent-diffusion/ldm/models/autoencoder.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  sd = torch.load(path, map_location="cpu")["state_dict"]
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
Global seed set to 23
initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All DDP processes registered. Starting ddp with 1 processes
----------------------------------------------------------------------------------------------------

/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/core/datamodule.py:423: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.
  rank_zero_deprecation(
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Set SLURM handle signals.

  | Name              | Type             | Params
-------------------------------------------------------
0 | model             | DiffusionWrapper | 294 M 
1 | model_ema         | LitEma           | 0     
2 | first_stage_model | AutoencoderKL    | 83.7 M
-------------------------------------------------------
294 M     Trainable params
83.7 M    Non-trainable params
378 M     Total params
1,514.483 Total estimated model params size (MB)
/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
Global seed set to 23
[rank0]:[W1207 18:19:24.502451451 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/torch/autograd/graph.py:769: UserWarning: Grad strides do not match bucket view strides. This may indicate grad was not created according to the gradient layout contract, or that the param's strides changed since DDP was constructed.  This is not an error, but may impair performance.
grad.sizes() = [192, 384, 1, 1], strides() = [384, 1, 384, 384]
bucket_view.sizes() = [192, 384, 1, 1], strides() = [384, 1, 1, 1] (Triggered internally at ../torch/csrc/distributed/c10d/reducer.cpp:327.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[rank0]: Traceback (most recent call last):
[rank0]:   File "main.py", line 719, in <module>
[rank0]:     trainer.fit(model, data)
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 553, in fit
[rank0]:     self._run(model)
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 918, in _run
[rank0]:     self._dispatch()
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 986, in _dispatch
[rank0]:     self.accelerator.start_training(self)
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/accelerators/accelerator.py", line 92, in start_training
[rank0]:     self.training_type_plugin.start_training(trainer)
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 161, in start_training
[rank0]:     self._results = trainer.run_stage()
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 996, in run_stage
[rank0]:     return self._run_train()
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py", line 1045, in _run_train
[rank0]:     self.fit_loop.run()
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 111, in run
[rank0]:     self.advance(*args, **kwargs)
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/fit_loop.py", line 200, in advance
[rank0]:     epoch_output = self.epoch_loop.run(train_dataloader)
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/base.py", line 111, in run
[rank0]:     self.advance(*args, **kwargs)
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py", line 118, in advance
[rank0]:     _, (batch, is_last) = next(dataloader_iter)
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/profiler/base.py", line 104, in profile_iterable
[rank0]:     value = next(iterator)
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/supporters.py", line 629, in prefetch_iterator
[rank0]:     for val in it:
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/supporters.py", line 546, in __next__
[rank0]:     return self.request_next_batch(self.loader_iters)
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/supporters.py", line 574, in request_next_batch
[rank0]:     return apply_to_collection(loader_iters, Iterator, next_fn)
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/utilities/apply_func.py", line 96, in apply_to_collection
[rank0]:     return function(data, *args, **kwargs)
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/pytorch_lightning/trainer/supporters.py", line 561, in next_fn
[rank0]:     batch = next(iterator)
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 630, in __next__
[rank0]:     data = self._next_data()
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1344, in _next_data
[rank0]:     return self._process_data(data)
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/torch/utils/data/dataloader.py", line 1370, in _process_data
[rank0]:     data.reraise()
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/torch/_utils.py", line 706, in reraise
[rank0]:     raise exception
[rank0]: PIL.UnidentifiedImageError: Caught UnidentifiedImageError in DataLoader worker process 1.
[rank0]: Original Traceback (most recent call last):
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py", line 309, in _worker_loop
[rank0]:     data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 52, in fetch
[rank0]:     data = [self.dataset[idx] for idx in possibly_batched_index]
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py", line 52, in <listcomp>
[rank0]:     data = [self.dataset[idx] for idx in possibly_batched_index]
[rank0]:   File "/oscar/scratch/daggarw5/latent-diffusion/ldm/data/lsun.py", line 48, in __getitem__
[rank0]:     image = Image.open(example["file_path_"])
[rank0]:   File "/users/daggarw5/.conda/envs/ldm/lib/python3.8/site-packages/PIL/Image.py", line 3498, in open
[rank0]:     raise UnidentifiedImageError(msg)
[rank0]: PIL.UnidentifiedImageError: cannot identify image file '/oscar/scratch/daggarw5/lsun/classroom/6ae459df981a263684d31e87e1e7b8e2209b4cb8.webp'

